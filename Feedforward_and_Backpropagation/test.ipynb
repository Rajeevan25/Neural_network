{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac13ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset as training and testing, then print out the shapes of the data matrices\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "# Display 5 random handwritten images from train_X and corresponding labels\n",
    "import random\n",
    "num_images = 5\n",
    "random_indices = random.sample(range(train_X.shape[0]), num_images)\n",
    "plt.figure(figsize=(10,5)) # Set the figure size\n",
    "for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.imshow(train_X[idx], cmap='gray')\n",
    "    plt.title(f\"Label: {train_y[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def extract_digits(X, y, d1, d2):\n",
    "    assert d1 in range(0, 10), \"d1 should be a number between 0 and 9 inclusive\"\n",
    "    assert d2 in range(0, 10), \"d2 should be a number between 0 and 9 inclusive\"\n",
    "    # Get the indices where Labels are d1 or d2\n",
    "    indices = np.where((y == d1) | (y == d2))[0]\n",
    "    # Extract the corresponding samples and Labels\n",
    "    X_extracted = X[indices]\n",
    "    y_extracted = y[indices]\n",
    "    return (X_extracted, y_extracted)\n",
    "\n",
    "def vectorize_images(X):\n",
    "    # Vectorize the images\n",
    "    X_vectorized = X.reshape(X.shape[0], -1)\n",
    "    # Transpose the vectorized result\n",
    "    X_transposed = X_vectorized.T\n",
    "    # Normalize the pixel values (divide each column by its max value)\n",
    "    X_normalized = X_transposed / X_transposed.max(axis=0)\n",
    "    return X_vectorized\n",
    "\n",
    "# Extract images and Labels for digits 1 and 5 from training and testing sets\n",
    "train_X_1_5, train_y_1_5 = extract_digits(train_X, train_y, 1, 5)\n",
    "test_X_1_5, test_y_1_5 = extract_digits(test_X, test_y, 1, 5)\n",
    "# Vectorize, transpose, and normalize the images\n",
    "train_X_1_5 = vectorize_images(train_X_1_5)\n",
    "test_X_1_5 = vectorize_images(test_X_1_5)\n",
    "# Convert the labels\n",
    "train_class_1_5 = np.where(train_y_1_5 == 1, 0, 1) # Convert 1 -> 0 and 5 -> 1\n",
    "test_class_1_5 = np.where(test_y_1_5 == 1, 0, 1)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    # Handling overflow by clipping the input to avoid large negative numbers\n",
    "    Z = np.clip(Z, -500, 500)\n",
    "    sigma = 1 / (1 + np.exp(-Z)) # Sigmoid function\n",
    "    return sigma\n",
    "\n",
    "def deriv_sigmoid(Y):\n",
    "    sigma_prime = Y * (1 - Y) # Derivative of sigmoid: σ'(z) = σ(z) * (1 - σ(z))\n",
    "    return sigma_prime\n",
    "\n",
    "def ReLu(Z):\n",
    "    relu = np.maximum(0, Z)\n",
    "    return relu\n",
    "\n",
    "def deriv_ReLu(Y):\n",
    "    relu_prime = np.where(Y > 0, 1, 0)\n",
    "    return relu_prime\n",
    "\n",
    "class NNet:\n",
    "    def __init__(self, input_size=784, output_size=1, batch_size=1000, hidden_layers=[1000, 500]):\n",
    "        self.Y = []\n",
    "        self.Z = []\n",
    "        self.W = []\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        layers = [input_size] + hidden_layers + [output_size]\n",
    "        L = len(hidden_layers) + 1\n",
    "        for i in range(1, L + 1):\n",
    "            self.Y.append(np.zeros((layers[i], batch_size)))\n",
    "            self.Z.append(np.zeros((layers[i], batch_size)))\n",
    "            self.W.append(2 * (np.random.rand(layers[i], layers[i-1] + 1) - 0.5))\n",
    "\n",
    "    def feedforward (self, X):\n",
    "    #TODO\n",
    "        L = len(self.hidden_layers) + 1\n",
    "        Y = [None] * L\n",
    "        Z = [None] * L\n",
    "        Y[0] = X  # Input to the first layer\n",
    "\n",
    "        for l in range(1, L):\n",
    "            if l == 1:\n",
    "                # Add a row of ones to accommodate the bias term for the first layer\n",
    "                Y_prev = np.vstack([Y[0], np.ones((1, Y[0].shape[1]))])\n",
    "            else:\n",
    "                # Add a row of ones to accommodate the bias term for subsequent layers\n",
    "                Y_prev = np.vstack([Y[l - 1], np.ones((1, Y[l - 1].shape[1]))])\n",
    "\n",
    "            # Calculate Z(l) with bias\n",
    "            Z[l] = np.dot(self.W[l - 1], Y_prev)\n",
    "\n",
    "            if l < L - 1:\n",
    "                Y[l] = self.sigmoid(Z[l])  # Apply sigmoid activation to hidden layers\n",
    "            else:\n",
    "                Y[l] = self.sigmoid(Z[l])  # Apply sigmoid activation to output layer\n",
    "\n",
    "        self.Y = Y  # Store computed Y's in the model\n",
    "        self.Z = Z  # Store computed Z's in the model\n",
    "        return self  # Return the modified model\n",
    "\n",
    "\n",
    "    def backpropagation(self, X, Y, eta=0.01):\n",
    "        model = self.feedforward(X)\n",
    "        L = len(model.Y)\n",
    "        dC_dZ = [np.zeros_like(Z) for Z in model.Z]\n",
    "        dC_dw = [np.zeros_like(W) for W in model.W]\n",
    "        dC_dY_prev = [np.zeros_like(Y) for Y in model.Y]\n",
    "        dC_dY_L = model.Y[-1] - Y\n",
    "        dC_dZ[-1] = deriv_sigmoid(model.Y[-1]) * dC_dY_L\n",
    "        for l in reversed(range(1, L)):\n",
    "            dC_dw[l] = np.dot(dC_dZ[l], np.vstack((model.Y[l-1], np.ones((1, model.batch_size)))))\n",
    "            dC_dY_prev[l-1] = np.dot(model.W[l].T, dC_dZ[l])[:-1, :]\n",
    "            dC_dZ[l-1] = deriv_ReLu(model.Y[l-1]) * dC_dY_prev[l-1]\n",
    "        for l in range(L):\n",
    "            model.W[l] -= eta * dC_dw[l]\n",
    "        return model\n",
    "\n",
    "def train_NNet(X, Y, epochs=20, batch_size=1000, eta=0.01):\n",
    "    num_samples = X.shape[1] # Assuming X has shape (features, samples)\n",
    "    # Convert Y to a 2D array if it's 1D\n",
    "    if Y.ndim == 1:\n",
    "        Y = Y[:, np.newaxis]\n",
    "    # Initialize the model (assumes a proper NNet class exists)\n",
    "    model = NNet(hidden_layers=[500, 250]) # Example initialization\n",
    "    cost_history = []\n",
    "    weight_changes = []\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        X = X[:, indices]\n",
    "        Y = Y[indices] # No need for additional axis\n",
    "        # Process data in mini-batches\n",
    "   \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X_batch = X[:, i:i+batch_size]\n",
    "            Y_batch = Y[i:i+batch_size]\n",
    "            \n",
    "            # Feedforward\n",
    "            model = model.feedforward(X_batch)\n",
    "            # Backpropagation\n",
    "            model = model.backpropagation(X_batch, Y_batch, eta)\n",
    "            # Compute cost\n",
    "            model = model.feedforward(X)\n",
    "            Y_pred = model.Y[-1]\n",
    "            cost = np.mean(np.square(Y_pred - Y))\n",
    "            cost_history.append(cost)\n",
    "            # Compute weight changes\n",
    "            weight_change = np.sum([np.linalg.norm(w) for w in model.W])\n",
    "            weight_changes.append(weight_change)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Cost: {cost}, Weight change: {weight_change}\")\n",
    "        # Plot cost history\n",
    "        plt.figure()\n",
    "        plt.plot(cost_history)\n",
    "        plt.title('Cost History')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.show()\n",
    "        # Plot weight changes\n",
    "        plt.figure()\n",
    "        plt.plot(weight_changes)\n",
    "        plt.title('Weight Change History')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Weight Change')\n",
    "        plt.show()\n",
    "    return model\n",
    "\n",
    "def test_model(test_data, test_labels, model, d1, d2):\n",
    "    L = len(model.hidden_layers) + 1\n",
    "    Y = test_data\n",
    "    for i in range(L):\n",
    "        Z = np.matmul(model.W[i], np.append(Y, np.array([np.ones(Y.shape[1])]), axis=0))\n",
    "        if i < L - 1:\n",
    "            Y = ReLu(Z)\n",
    "        else:\n",
    "            Y = sigmoid(Z)\n",
    "    Y = np.where(Y >= 0.5, 1, 0)\n",
    "    Y_predicted = np.where(Y == 0, d1, d2)\n",
    "    acc = accuracy_score(test_labels, Y_predicted)\n",
    "    return (acc, Y_predicted)\n",
    "\n",
    "def evaluate_model(test_data, test_labels, model, d1, d2):\n",
    "    acc, Y_predicted = test_model(test_data, test_labels, model, d1, d2)\n",
    "    cm = confusion_matrix(test_labels, Y_predicted, labels=[d1, d2])\n",
    "    return acc, cm\n",
    "\n",
    "def hyperparameter_tuning(train_X, train_y, test_X, test_y, batch_sizes, etas, hidden_layers_options):\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    for batch_size in batch_sizes:\n",
    "        for eta in etas:\n",
    "            for hidden_layers in hidden_layers_options:\n",
    "                model = NNet(hidden_layers=hidden_layers)\n",
    "                model = train_NNet(train_X, train_y, epochs=20, batch_size=batch_size, eta=eta)\n",
    "                acc, cm = evaluate_model(test_X, test_y, model, 1, 5)\n",
    "                print(f\"Batch size: {batch_size}, eta: {eta}, Hidden layers: {hidden_layers}, accuracy: {acc}\")\n",
    "                if acc > best_accuracy:\n",
    "                    best_accuracy = acc\n",
    "                    best_params = (batch_size, eta, hidden_layers)\n",
    "                    best_cm = cm\n",
    "    print(f\"Best accuracy: {best_accuracy} with batch size: {best_params[0]}, eta: {best_params[1]}, hidden layers: {best_params[2]}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(best_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[1, 5], yticklabels=[1, 5])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "151542b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (500,785) and (12164,784) not aligned: 785 (dim 1) != 12164 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m hidden_layers_options \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m250\u001b[39m]]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_1_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_class_1_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_X_1_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_class_1_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layers_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m accuracy, confusion_mat \u001b[38;5;241m=\u001b[39m evaluate_model(test_X_1_5, test_class_1_5, model, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 209\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[1;34m(train_X, train_y, test_X, test_y, batch_sizes, etas, hidden_layers_options)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_layers \u001b[38;5;129;01min\u001b[39;00m hidden_layers_options:\n\u001b[0;32m    208\u001b[0m     model \u001b[38;5;241m=\u001b[39m NNet(hidden_layers\u001b[38;5;241m=\u001b[39mhidden_layers)\n\u001b[1;32m--> 209\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_NNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     acc, cm \u001b[38;5;241m=\u001b[39m evaluate_model(test_X, test_y, model, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Hidden layers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 155\u001b[0m, in \u001b[0;36mtrain_NNet\u001b[1;34m(X, Y, epochs, batch_size, eta)\u001b[0m\n\u001b[0;32m    152\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m Y[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Feedforward\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeedforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m    157\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbackpropagation(X_batch, Y_batch, eta)\n",
      "Cell \u001b[1;32mIn[23], line 105\u001b[0m, in \u001b[0;36mNNet.feedforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    102\u001b[0m     Y_prev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([Y[l \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, Y[l \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))])\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Calculate Z(l) with bias\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m Z[l] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_prev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m<\u001b[39m L \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    108\u001b[0m     Y[l] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(Z[l])  \u001b[38;5;66;03m# Apply sigmoid activation to hidden layers\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (500,785) and (12164,784) not aligned: 785 (dim 1) != 12164 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Parameters for training\n",
    "batch_sizes = [1000]\n",
    "etas = [0.01]\n",
    "hidden_layers_options = [[500, 250]]\n",
    "\n",
    "# Train the model\n",
    "model = hyperparameter_tuning(train_X_1_5, train_class_1_5, test_X_1_5, test_class_1_5, batch_sizes, etas, hidden_layers_options)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, confusion_mat = evaluate_model(test_X_1_5, test_class_1_5, model, 1, 5)\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Confusion matrix:\\n{confusion_mat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e093e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273da88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
